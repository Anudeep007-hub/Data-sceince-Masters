{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is data encoding? How is it useful in data science?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data encoding is the process of converting data into a specific format that can be efficiently used by computer systems. This often involves transforming categorical or text data into numerical values, which can then be utilized by various data analysis and machine learning algorithms. Here are a few common methods of data encoding and their importance in data science:\n",
    "\n",
    "1. **Label Encoding**:\n",
    "   - **Description**: This technique assigns a unique integer to each category in the data. For instance, if you have a column with categories \"apple,\" \"banana,\" and \"cherry,\" they could be encoded as 0, 1, and 2, respectively.\n",
    "   - **Use Case**: Useful when the categorical data is ordinal, meaning there is an inherent order in the categories.\n",
    "\n",
    "2. **One-Hot Encoding**:\n",
    "   - **Description**: This method creates a new binary column for each category. For example, for the categories \"apple,\" \"banana,\" and \"cherry,\" it creates three new columns: \"is_apple,\" \"is_banana,\" and \"is_cherry,\" with binary values indicating the presence of the category.\n",
    "   - **Use Case**: Ideal for nominal data, where there is no ordinal relationship among the categories.\n",
    "\n",
    "3. **Binary Encoding**:\n",
    "   - **Description**: Converts categories into binary digits. For example, for the categories \"apple,\" \"banana,\" and \"cherry,\" you could represent them as binary values 01, 10, and 11.\n",
    "   - **Use Case**: Helps reduce the dimensionality issue associated with one-hot encoding, especially useful for datasets with a high number of categories.\n",
    "\n",
    "4. **Frequency Encoding**:\n",
    "   - **Description**: Assigns the frequency of each category to its occurrences in the data. For example, if \"apple\" appears 50 times, \"banana\" 30 times, and \"cherry\" 20 times, these frequencies are used as the encoded values.\n",
    "   - **Use Case**: Useful when the frequency of occurrence is relevant to the problem at hand.\n",
    "\n",
    "5. **Mean Encoding**:\n",
    "   - **Description**: Uses the mean of the target variable for each category as the encoded value. For example, if predicting house prices, each neighborhood could be encoded by the average house price in that neighborhood.\n",
    "   - **Use Case**: Useful in cases where categories have a significant impact on the target variable.\n",
    "\n",
    "### Importance in Data Science\n",
    "\n",
    "- **Algorithm Compatibility**: Many machine learning algorithms require numerical input. Data encoding ensures categorical data can be effectively used by these algorithms.\n",
    "- **Improved Model Performance**: Proper encoding can help the model understand the relationships and patterns in the data better, leading to improved accuracy and performance.\n",
    "- **Feature Engineering**: Encoding is a crucial step in feature engineering, which involves creating new features that can enhance model performance.\n",
    "- **Handling High Cardinality**: Techniques like binary and frequency encoding help manage datasets with high cardinality (many unique categories) without creating too many features, which can be computationally expensive and lead to overfitting.\n",
    "\n",
    "In summary, data encoding transforms raw data into a format suitable for analysis, enabling the effective application of machine learning models and improving overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nominal encoding, also known as categorical encoding, is the process of converting categorical data into a numerical format, suitable for machine learning models. This is especially useful when the categories do not have an inherent order. One common technique for nominal encoding is **One-Hot Encoding**.\n",
    "\n",
    "### Example of Nominal Encoding: One-Hot Encoding\n",
    "\n",
    "**Real-World Scenario: Predicting Customer Churn for a Telecom Company**\n",
    "\n",
    "Let's consider a telecom company that wants to predict customer churn based on several features, including the type of service plan each customer is using. The service plans are categorical and include options like \"Basic,\" \"Silver,\" and \"Gold.\"\n",
    "\n",
    "#### Step-by-Step Process:\n",
    "\n",
    "1. **Data Collection**:\n",
    "   The dataset might look like this:\n",
    "   ```\n",
    "   CustomerID | ServicePlan | MonthlyCharges | Churn\n",
    "   ------------------------------------------------\n",
    "   1          | Basic       | 20.00          | No\n",
    "   2          | Silver      | 35.00          | Yes\n",
    "   3          | Gold        | 50.00          | No\n",
    "   4          | Basic       | 20.00          | No\n",
    "   5          | Silver      | 35.00          | Yes\n",
    "   ```\n",
    "\n",
    "2. **Applying One-Hot Encoding**:\n",
    "   Transform the \"ServicePlan\" column using One-Hot Encoding. This will create a new binary column for each category in the \"ServicePlan\" column.\n",
    "\n",
    "   The transformed dataset will look like this:\n",
    "   ```\n",
    "   CustomerID | Basic | Silver | Gold | MonthlyCharges | Churn\n",
    "   -----------------------------------------------------------\n",
    "   1          | 1     | 0      | 0    | 20.00          | No\n",
    "   2          | 0     | 1      | 0    | 35.00          | Yes\n",
    "   3          | 0     | 0      | 1    | 50.00          | No\n",
    "   4          | 1     | 0      | 0    | 20.00          | No\n",
    "   5          | 0     | 1      | 0    | 35.00          | Yes\n",
    "   ```\n",
    "\n",
    "3. **Model Training**:\n",
    "   With the one-hot encoded data, you can now train a machine learning model, such as logistic regression, decision tree, or any other classifier, to predict customer churn based on the available features.\n",
    "\n",
    "4. **Interpreting Results**:\n",
    "   The model can use the encoded features to understand the impact of different service plans on customer churn. For instance, it might identify that customers on the \"Silver\" plan are more likely to churn.\n",
    "\n",
    "### Benefits of One-Hot Encoding:\n",
    "\n",
    "- **Preserves Information**: Ensures that no information about the categories is lost in the transformation process.\n",
    "- **Avoids Ordinality Assumption**: Unlike label encoding, one-hot encoding does not assume any inherent order among the categories, which is suitable for nominal data.\n",
    "- **Algorithm Compatibility**: Many machine learning algorithms work better with numerical input, making one-hot encoding a standard preprocessing step.\n",
    "\n",
    "### Use Case in Real-World:\n",
    "\n",
    "Imagine you are working on a project to predict customer preferences in an e-commerce platform. The platform offers various product categories such as \"Electronics,\" \"Clothing,\" \"Home Appliances,\" etc. By applying nominal encoding, you can convert these product categories into a numerical format, allowing your machine learning model to understand and predict customer behavior more effectively.\n",
    "\n",
    "In summary, nominal encoding, particularly one-hot encoding, is a powerful technique to transform categorical data into a format that can be utilized by machine learning algorithms, enhancing model performance and prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nominal encoding, also known as label encoding, assigns a unique integer to each category, while one-hot encoding creates a binary column for each category. Nominal encoding is preferred over one-hot encoding in situations where:\n",
    "\n",
    "1. **High Cardinality**: When the categorical variable has a large number of unique categories, one-hot encoding would create an impractically large number of columns, leading to high memory usage and computational inefficiency.\n",
    "2. **Tree-Based Models**: Algorithms like decision trees and random forests can handle label encoded data well because they split data based on feature values, so the ordinal nature imposed by label encoding is not an issue.\n",
    "3. **When Category Information is Sufficient**: In some cases, the categories themselves carry enough information, and the relationship between categories and the target variable can be captured without creating additional binary columns.\n",
    "\n",
    "### Practical Example: Predicting Job Titles in a Company\n",
    "\n",
    "#### Scenario:\n",
    "A company wants to predict the department in which a new employee will work based on their job title. The dataset includes a categorical variable \"JobTitle\" with high cardinality, i.e., many unique job titles.\n",
    "\n",
    "#### Dataset Example:\n",
    "```\n",
    "EmployeeID | JobTitle              | Department\n",
    "----------------------------------------------\n",
    "1          | Software Engineer     | IT\n",
    "2          | Data Scientist        | Data Analytics\n",
    "3          | HR Manager            | Human Resources\n",
    "4          | Sales Executive       | Sales\n",
    "5          | Marketing Specialist  | Marketing\n",
    "6          | Software Engineer II  | IT\n",
    "...\n",
    "```\n",
    "\n",
    "#### Applying Nominal Encoding:\n",
    "\n",
    "1. **Label Encoding \"JobTitle\"**:\n",
    "   Assign a unique integer to each job title.\n",
    "   ```\n",
    "   JobTitle               | EncodedJobTitle\n",
    "   ----------------------------------------\n",
    "   Software Engineer      | 1\n",
    "   Data Scientist         | 2\n",
    "   HR Manager             | 3\n",
    "   Sales Executive        | 4\n",
    "   Marketing Specialist   | 5\n",
    "   Software Engineer II   | 6\n",
    "   ...\n",
    "   ```\n",
    "\n",
    "   The transformed dataset will look like this:\n",
    "   ```\n",
    "   EmployeeID | EncodedJobTitle | Department\n",
    "   -----------------------------------------\n",
    "   1          | 1               | IT\n",
    "   2          | 2               | Data Analytics\n",
    "   3          | 3               | Human Resources\n",
    "   4          | 4               | Sales\n",
    "   5          | 5               | Marketing\n",
    "   6          | 6               | IT\n",
    "   ...\n",
    "   ```\n",
    "\n",
    "2. **Model Training**:\n",
    "   Use a decision tree classifier to predict the \"Department\" based on the \"EncodedJobTitle\".\n",
    "\n",
    "3. **Interpreting Results**:\n",
    "   The model will learn the relationship between the encoded job titles and the departments. Decision trees can handle the numerical labels effectively and split data based on the job title values to make predictions.\n",
    "\n",
    "### Why Nominal Encoding is Preferred Here:\n",
    "\n",
    "- **High Cardinality**: The \"JobTitle\" variable has many unique values, and one-hot encoding would create a large number of columns, making the dataset sparse and increasing computational complexity.\n",
    "- **Tree-Based Model Compatibility**: Decision trees and similar algorithms can work well with label encoded data because they do not assume any order in the encoded values.\n",
    "- **Efficiency**: Label encoding results in a single column, reducing memory usage and making the model training process more efficient.\n",
    "\n",
    "In this example, nominal encoding is a practical choice to handle the high cardinality of the job titles and efficiently train a model to predict the department, demonstrating its advantages over one-hot encoding in specific situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding technique would you use to transform this data into a format suitable for machine learning algorithms? Explain why you made this choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a dataset containing categorical data with 5 unique values, the encoding technique choice depends on the specifics of the dataset and the machine learning algorithm you plan to use. Here are the two primary options:\n",
    "\n",
    "1. **One-Hot Encoding**\n",
    "2. **Label Encoding**\n",
    "\n",
    "### One-Hot Encoding\n",
    "\n",
    "#### Description:\n",
    "One-hot encoding creates a new binary column for each unique category value. Each column represents a category, and a row contains a 1 in the column corresponding to the category and 0s in all other columns.\n",
    "\n",
    "#### Example:\n",
    "For a categorical feature \"Color\" with values [\"Red\", \"Blue\", \"Green\", \"Yellow\", \"Black\"], one-hot encoding would create the following columns:\n",
    "```\n",
    "Color      | Red | Blue | Green | Yellow | Black\n",
    "-----------------------------------------------\n",
    "Red        | 1   | 0    | 0     | 0      | 0\n",
    "Blue       | 0   | 1    | 0     | 0      | 0\n",
    "Green      | 0   | 0    | 1     | 0      | 0\n",
    "Yellow     | 0   | 0    | 0     | 1      | 0\n",
    "Black      | 0   | 0    | 0     | 0      | 1\n",
    "```\n",
    "\n",
    "#### Why Choose One-Hot Encoding:\n",
    "- **No Ordinal Relationship**: If the categories do not have an inherent order, one-hot encoding is a better choice to avoid implying any ordinal relationship between them.\n",
    "- **Algorithm Compatibility**: Many algorithms, especially linear models, neural networks, and distance-based algorithms (like KNN), perform better with one-hot encoded data.\n",
    "\n",
    "### Label Encoding\n",
    "\n",
    "#### Description:\n",
    "Label encoding assigns a unique integer to each category value.\n",
    "\n",
    "#### Example:\n",
    "For the same \"Color\" feature, label encoding would transform it as follows:\n",
    "```\n",
    "Color   | EncodedValue\n",
    "----------------------\n",
    "Red     | 0\n",
    "Blue    | 1\n",
    "Green   | 2\n",
    "Yellow  | 3\n",
    "Black   | 4\n",
    "```\n",
    "\n",
    "#### Why Choose Label Encoding:\n",
    "- **Ordinal Relationship**: If the categories have an inherent order (e.g., \"low,\" \"medium,\" \"high\"), label encoding is suitable.\n",
    "- **Tree-Based Models**: Decision trees and ensemble methods (e.g., Random Forest, Gradient Boosting) can handle label encoded data well, as they split data based on feature values without assuming any ordinal relationship.\n",
    "\n",
    "### Choice for 5 Unique Values\n",
    "\n",
    "For a dataset with 5 unique values, **one-hot encoding** is generally preferred unless there's a specific reason to use label encoding (such as an ordinal relationship or if you're using tree-based models).\n",
    "\n",
    "#### Reasons for Choosing One-Hot Encoding:\n",
    "1. **Avoid Implied Ordinality**: One-hot encoding avoids any implicit ordering in the data, which can mislead algorithms that assume numerical relationships.\n",
    "2. **Algorithm Performance**: Most machine learning algorithms that work with categorical data (e.g., logistic regression, neural networks) perform better with one-hot encoded features.\n",
    "3. **Manageable Number of Columns**: With only 5 unique values, one-hot encoding results in 5 additional columns, which is manageable in terms of computational complexity and memory usage.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "For a dataset with 5 unique categorical values, one-hot encoding is typically the best choice. It prevents the introduction of spurious ordinal relationships and is well-suited for most machine learning algorithms. However, if you are using tree-based models and want to keep the feature space smaller, label encoding could be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to transform the categorical data, how many new columns would be created? Show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine how many new columns would be created if you were to use nominal encoding (one-hot encoding) for the categorical data, you need to know the number of unique values in each of the categorical columns. \n",
    "\n",
    "Let's assume the following:\n",
    "- Column 1 (Categorical) has \\( U_1 \\) unique values.\n",
    "- Column 2 (Categorical) has \\( U_2 \\) unique values.\n",
    "\n",
    "When applying one-hot encoding, each unique value in a categorical column is transformed into a separate binary column. The number of new columns created for each categorical column is equal to the number of unique values in that column.\n",
    "\n",
    "### Calculation:\n",
    "\n",
    "For Column 1:\n",
    "- If Column 1 has \\( U_1 \\) unique values, one-hot encoding will create \\( U_1 \\) new columns.\n",
    "\n",
    "For Column 2:\n",
    "- If Column 2 has \\( U_2 \\) unique values, one-hot encoding will create \\( U_2 \\) new columns.\n",
    "\n",
    "Therefore, the total number of new columns created would be:\n",
    "\\[ U_1 + U_2 \\]\n",
    "\n",
    "### Example Calculation:\n",
    "\n",
    "Assume the following unique values in the categorical columns:\n",
    "- Column 1 has 4 unique values.\n",
    "- Column 2 has 3 unique values.\n",
    "\n",
    "Applying one-hot encoding:\n",
    "\n",
    "1. Column 1 with 4 unique values will be transformed into 4 binary columns.\n",
    "2. Column 2 with 3 unique values will be transformed into 3 binary columns.\n",
    "\n",
    "Total new columns created:\n",
    "\\[ 4 + 3 = 7 \\]\n",
    "\n",
    "### Final Dataset Structure:\n",
    "\n",
    "- Original numerical columns: 3 columns\n",
    "- New one-hot encoded columns: 7 columns\n",
    "\n",
    "Total number of columns in the transformed dataset:\n",
    "\\[ 3 + 7 = 10 \\]\n",
    "\n",
    "### Summary\n",
    "\n",
    "After applying one-hot encoding to the two categorical columns, 7 new columns would be created, resulting in a total of 10 columns in the dataset. The final dataset will have 1000 rows and 10 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. You are working with a dataset containing information about different types of animals, including their species, habitat, and diet. Which encoding technique would you use to transform the categorical data into a format suitable for machine learning algorithms? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform the categorical data in a dataset containing information about different types of animals, including their species, habitat, and diet, into a format suitable for machine learning algorithms, the most appropriate encoding technique would generally be **One-Hot Encoding**. Here’s the justification:\n",
    "\n",
    "### Characteristics of the Data\n",
    "\n",
    "1. **Nominal Nature of Categories**:\n",
    "   - **Species**: Different species of animals (e.g., lion, tiger, elephant) are distinct categories without any inherent order.\n",
    "   - **Habitat**: Habitats (e.g., forest, savannah, ocean) are distinct categories without any inherent order.\n",
    "   - **Diet**: Diet types (e.g., herbivore, carnivore, omnivore) are distinct categories without any inherent order.\n",
    "\n",
    "### Reasons for Choosing One-Hot Encoding\n",
    "\n",
    "1. **No Ordinal Relationship**:\n",
    "   - The categorical variables (species, habitat, diet) are nominal, meaning there is no inherent ranking or order among them. One-hot encoding is well-suited for such data as it does not assume any ordinal relationship.\n",
    "\n",
    "2. **Avoiding Implicit Ordinality**:\n",
    "   - Using label encoding for nominal data might introduce an implicit ordinal relationship, which can mislead certain machine learning algorithms that might assume some sort of ranking or distance between the encoded values.\n",
    "\n",
    "3. **Algorithm Compatibility**:\n",
    "   - Many machine learning algorithms, such as linear models (e.g., logistic regression), neural networks, and distance-based algorithms (e.g., KNN), perform better with one-hot encoded data.\n",
    "\n",
    "### Example:\n",
    "\n",
    "Suppose the dataset looks like this:\n",
    "```\n",
    "Animal  | Species | Habitat | Diet\n",
    "-------------------------------------\n",
    "Animal1 | Lion    | Savanna | Carnivore\n",
    "Animal2 | Elephant| Forest  | Herbivore\n",
    "Animal3 | Shark   | Ocean   | Carnivore\n",
    "Animal4 | Deer    | Forest  | Herbivore\n",
    "Animal5 | Bear    | Mountain| Omnivore\n",
    "```\n",
    "\n",
    "### Applying One-Hot Encoding\n",
    "\n",
    "#### Step-by-Step Process:\n",
    "\n",
    "1. **Species**: Assume we have 5 unique species.\n",
    "   - Lion, Elephant, Shark, Deer, Bear\n",
    "\n",
    "2. **Habitat**: Assume we have 4 unique habitats.\n",
    "   - Savanna, Forest, Ocean, Mountain\n",
    "\n",
    "3. **Diet**: Assume we have 3 unique diet types.\n",
    "   - Carnivore, Herbivore, Omnivore\n",
    "\n",
    "After one-hot encoding, the dataset will have the following binary columns for each category:\n",
    "\n",
    "- **Species**: Lion, Elephant, Shark, Deer, Bear\n",
    "- **Habitat**: Savanna, Forest, Ocean, Mountain\n",
    "- **Diet**: Carnivore, Herbivore, Omnivore\n",
    "\n",
    "### Transformed Dataset:\n",
    "```\n",
    "Animal  | Lion | Elephant | Shark | Deer | Bear | Savanna | Forest | Ocean | Mountain | Carnivore | Herbivore | Omnivore\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "Animal1 | 1    | 0        | 0     | 0    | 0    | 1       | 0      | 0     | 0        | 1         | 0         | 0\n",
    "Animal2 | 0    | 1        | 0     | 0    | 0    | 0       | 1      | 0     | 0        | 0         | 1         | 0\n",
    "Animal3 | 0    | 0        | 1     | 0    | 0    | 0       | 0      | 1     | 0        | 1         | 0         | 0\n",
    "Animal4 | 0    | 0        | 0     | 1    | 0    | 0       | 1      | 0     | 0        | 0         | 1         | 0\n",
    "Animal5 | 0    | 0        | 0     | 0    | 1    | 0       | 0      | 0     | 1        | 0         | 0         | 1\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "One-hot encoding is the most appropriate choice for transforming the categorical data about animal species, habitat, and diet into a format suitable for machine learning algorithms. This method avoids the introduction of spurious ordinal relationships and ensures compatibility with a wide range of algorithms, facilitating better model performance and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7.You are working on a project that involves predicting customer churn for a telecommunications company. You have a dataset with 5 features, including the customer's gender, age, contract type, monthly charges, and tenure. Which encoding technique(s) would you use to transform the categorical data into numerical data? Provide a step-by-step explanation of how you would implement the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To predict customer churn for a telecommunications company using a dataset with the features: gender, age, contract type, monthly charges, and tenure, you'll need to transform the categorical data into numerical data. Here’s how you can approach this:\n",
    "\n",
    "### Features in the Dataset:\n",
    "\n",
    "1. **Gender**: Categorical (e.g., Male, Female)\n",
    "2. **Age**: Numerical\n",
    "3. **Contract Type**: Categorical (e.g., Month-to-month, One year, Two year)\n",
    "4. **Monthly Charges**: Numerical\n",
    "5. **Tenure**: Numerical\n",
    "\n",
    "### Encoding Techniques:\n",
    "\n",
    "- **Gender**: Binary encoding or one-hot encoding.\n",
    "- **Contract Type**: One-hot encoding.\n",
    "\n",
    "### Step-by-Step Explanation:\n",
    "\n",
    "#### 1. Analyzing the Features:\n",
    "\n",
    "- **Gender**: This is a binary categorical feature with two unique values (Male, Female).\n",
    "- **Contract Type**: This categorical feature has three unique values (Month-to-month, One year, Two year).\n",
    "- **Age, Monthly Charges, Tenure**: These are numerical features and do not need encoding.\n",
    "\n",
    "#### 2. Encoding Gender:\n",
    "\n",
    "Since Gender has only two unique values, binary encoding can be used. However, one-hot encoding is also an option. For simplicity, let's use binary encoding:\n",
    "- **Male** = 0\n",
    "- **Female** = 1\n",
    "\n",
    "#### 3. Encoding Contract Type:\n",
    "\n",
    "Contract Type has three unique values, so one-hot encoding is appropriate. This will create three new binary columns.\n",
    "\n",
    "#### 4. Implementing the Encoding:\n",
    "\n",
    "Here’s a step-by-step guide to implement the encoding using Python's `pandas` library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender  Age  Monthly Charges  Tenure  Contract_Month-to-month  \\\n",
      "0       0   25             70.5       1                     True   \n",
      "1       1   30             85.0      12                    False   \n",
      "2       0   45             60.0      24                     True   \n",
      "3       1   35             95.5      36                    False   \n",
      "4       0   50             75.0      48                    False   \n",
      "\n",
      "   Contract_One year  Contract_Two year  \n",
      "0              False              False  \n",
      "1               True              False  \n",
      "2              False              False  \n",
      "3              False               True  \n",
      "4               True              False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'Age': [25, 30, 45, 35, 50],\n",
    "    'Contract Type': ['Month-to-month', 'One year', 'Month-to-month', 'Two year', 'One year'],\n",
    "    'Monthly Charges': [70.5, 85.0, 60.0, 95.5, 75.0],\n",
    "    'Tenure': [1, 12, 24, 36, 48],\n",
    "}\n",
    "\n",
    "# Creating DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Binary encoding for Gender\n",
    "df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "# One-hot encoding for Contract Type\n",
    "df = pd.get_dummies(df, columns=['Contract Type'], prefix='Contract')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Transformed DataFrame:\n",
    "\n",
    "The resulting DataFrame after encoding will look like this:\n",
    "\n",
    "```\n",
    "   Gender  Age  Monthly Charges  Tenure  Contract_Month-to-month  Contract_One year  Contract_Two year\n",
    "0       0   25             70.5       1                        1                  0                  0\n",
    "1       1   30             85.0      12                        0                  1                  0\n",
    "2       0   45             60.0      24                        1                  0                  0\n",
    "3       1   35             95.5      36                        0                  0                  1\n",
    "4       0   50             75.0      48                        0                  1                  0\n",
    "```\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **Gender** is encoded using binary encoding.\n",
    "- **Contract Type** is encoded using one-hot encoding, resulting in three new columns.\n",
    "\n",
    "By applying these encoding techniques, the categorical data is transformed into numerical data, making it suitable for use in machine learning algorithms. This preprocessing step ensures that the model can interpret and utilize the information effectively to predict customer churn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
